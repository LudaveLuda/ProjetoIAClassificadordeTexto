{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF49U3_OWhdQ"
      },
      "source": [
        "#**Integrantes**\n",
        "\n",
        "  Lucca Costa Lima D'Avila - 171903\n",
        "\n",
        "  Henrique Casarini Firmino - 180185\n",
        "\n",
        "  Carlos Eduardo Ferreira da Silva - 223748\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8LDNn4XGBl6"
      },
      "source": [
        "#Neste trabalho, iremos demonstrar a habilidade do FNet em atingir resultados comparáveis com um modelo Transformer em um caso de classificação de texto.\n",
        "#Para isso, utilizaremos um dataset do IMDb com uma coleção de críticas de filmes classificados como positivo ou negativo.\n",
        "#Para construir o tokenizer, modelo etc. usaremos componentes do KerasNLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGKf5FwG4bv",
        "outputId": "eb7efe62-2139-4cbb-849d-d7774a52d6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_nlp\n",
            "  Downloading keras_nlp-0.3.1-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.21.6)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_nlp) (3.0.9)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.50.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.28.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (2.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras_nlp) (3.2.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 8.0 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 63.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-text, keras-nlp\n",
            "Successfully installed keras-nlp-0.3.1 tensorflow-text-2.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgIDpIVRFnE7"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ7gVDCAFtFQ"
      },
      "source": [
        "#Embedding A\n",
        "\n",
        "Parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBTXBdVitBQ"
      },
      "source": [
        "## Sequence Length Pequeno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXbrXtHeFvb9"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 128\n",
        "INTERMEDIATE_DIM = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hbcVS7F3aC"
      },
      "source": [
        "#Carregando o dataset.\n",
        "O dataset usado é do IMDb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQX1TKwaF13j",
        "outputId": "91fb08a0-3ef8-45d7-c168-9210c90eafa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-02 15:56:41--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  23.5MB/s    in 3.4s    \n",
            "\n",
            "2022-12-02 15:56:45 (23.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEmWIRmDGwjx",
        "outputId": "ea18c14e-7b0e-4b77-e8a2-5ffaa24a907c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['imdbEr.txt', 'test', 'imdb.vocab', 'README', 'train']\n",
            "['pos', 'urls_pos.txt', 'unsup', 'labeledBow.feat', 'urls_unsup.txt', 'unsupBow.feat', 'neg', 'urls_neg.txt']\n",
            "['pos', 'urls_pos.txt', 'labeledBow.feat', 'neg', 'urls_neg.txt']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(\"./aclImdb\"))\n",
        "print(os.listdir(\"./aclImdb/train\"))\n",
        "print(os.listdir(\"./aclImdb/test\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taF5B7J1H26b"
      },
      "source": [
        "#O diretório contém dois sub-diretórios (train e test). Cada um deles possui duas pastas (pos e neg) para críticas positivas e negativas. Antes de carregar o dataset, vamos deletar a pasta train/unsup, já que ela possui apenas críticas sem classificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPQ8jmV0IU2t"
      },
      "outputs": [],
      "source": [
        "!rm -rf aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXgimfEuIZRA"
      },
      "source": [
        "#Vamos usar o \"keras.utils.text_dataset_from_directory\" para gerar o dataset rotulado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpRhnhoWIqLd",
        "outputId": "907725d0-fac8-4b52-c739-47a1afc10b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKTDN766ItK2"
      },
      "source": [
        "#Convertendo o texto para minúsculas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24EYhM8QIxJm"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joq_h92KI1Sq"
      },
      "source": [
        "#Imprimindo alguns exemplos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqo2M-37IzXt",
        "outputId": "705cc698-29b8-4c5d-ae3e-96189b5c85db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'an illegal immigrant resists the social support system causing dire consequences for many. well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. the feeling of being lost in the big city is effectively conveyed. the little person lost in the big society is something to which we can all relate, but i cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"to get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. how beautifully the opening scene leading to the expulsion of gino establishes the theme of moral ambiguity! note the way music introduces the characters as we are led inside giovanna's marriage. don't expect to find much here of the political life of italy in 1943. that's not what this is about. on the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. by the end of the film we there are moments antonioni-like landscape that has more to do with the inner life of the characters than with real places. this is one of my favorite visconti films.\"\n",
            "1\n",
            "b'\"hollywood hotel\" has relationships to many films like \"ella cinders\" and \"merton of the movies\" about someone winning a contest including a contract to make films in hollywood, only to find the road to stardom either paved with pitfalls or non-existent. in fact, as i was watching it tonight, on turner classic movies, i was considering whether or not the authors of the later musical classic \"singing in the rain\" may have taken some of their ideas from \"hollywood hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"hollywood hotel\" is a fascinating example of movie making in the 1930s. among the supporting players is louella parsons, playing herself (and, despite some negative comments i\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). she is not the only real person in the script. make-up specialist perc westmore briefly appears as himself to try to make one character resemble another.<br /><br />this film also was one of the first in the career of young mr. ronald reagan, playing a radio interviewer at a movie premiere. reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody dick powell is about to take over the microphone when it should be used with more important people.<br /><br />dick powell has won a hollywood contract in a contest, and is leaving his job as a saxophonist in benny goodman\\'s band. the beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to powell. they end up singing \"hooray for hollywood\". the interesting thing about this wonderful number is that a lyric has been left out on purpose. throughout the johnny mercer lyrics are references to such hollywood as max factor the make-up king, rin tin tin, and even a hint of tarzan. but the original song lyric referred to looking like tyrone power. obviously jack warner and his brothers were not going to advertise the leading man of 20th century fox, and the name donald duck was substituted. in any event the number showed the singers and instrumentalists of goodman\\'s orchestra at their best. so did a later five minute section of the film, where the band is rehearsing.<br /><br />powell leaves the band and his girl friend (frances langford) and goes to hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). he is met by allen joslyn, the publicist of the studio (the owner is grant mitchell). joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. he parks powell at a room at the hollywood hotel, which is also where the studio\\'s temperamental star (lola lane) lives with her father (hugh herbert), her sister (mabel todd), and her sensible if cynical assistant (glenda farrell). lane is like jean hagen in \"singing in the rain\", except her speaking voice is good. her version of \"dan lockwood\" is one \"alexander dupre\" (alan mowbray, scene stealing with ease several times). the only difference is that mowbray is not a nice guy like gene kelly was, and lane (when not wrapped up in her ego) is fully aware of it. having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. joslyn finds a double for her (lola\\'s real life sister rosemary lane), and rosemary is made up to play the star at the premiere and the follow-up party. but she attends with powell (joslyn wanting someone who doesn\\'t know the real lola). this leads to powell knocking down mowbray when the latter makes a pest of himself. but otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />the complications deal with lola coming back and slapping powell in the face, after mowbray complains he was attacked by powell (\"and his gang of hoodlums\"). powell\\'s contract is bought out. working with photographer turned agent ted healey (actually not too bad in this film - he even tries to do a jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered edgar kennedy (the number of broken dishes and singing customers in the restaurant give edgar plenty of time to do his slow burns with gusto). eventually powell gets a \"break\" by being hired to be dupre\\'s singing voice in a rip-off of \"gone with the wind\". this leads to the final section of the film, when rosemary lane, herbert, and healey help give powell his chance to show it\\'s his voice, not mowbrays.<br /><br />it\\'s quite a cute and appealing film even now. the worst aspects are due to it\\'s time. several jokes concerning african-americans are no longer tolerable (while trying to photograph powell as he arrives in hollywood, healey accidentally photographs a porter, and mentions to joslyn to watch out, powell photographs too darkly - get the point?). also a bit with curt bois as a fashion designer for lola lane, who is (shall we say) too high strung is not very tolerable either. herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. and an incident where healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in december 1937. but most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiM_N7BVI9Pq"
      },
      "source": [
        "#Tokenizando os dados\n",
        "Utilizaremos o keras_nlp.tokenizers.WordPieceTokenizer para fazer esse processo. Ele recebe um vocabulário WordPiece e possui funções para tokenizar o texto, e destokenizar uma sequência de tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv7wqlimJcRs"
      },
      "outputs": [],
      "source": [
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    bert_vocab_args = dict(\n",
        "        # Tamanho do vocabulário de destino\n",
        "        vocab_size=vocab_size,\n",
        "        # Tokens reservados que devem ser incluídos no vocabulário \n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Argumentos para `text.BertTokenizer`\n",
        "        bert_tokenizer_params={\"lower_case\": True},\n",
        "    )\n",
        "\n",
        "    # Extrai amostras de texto (remove os rótulos).\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n",
        "    )\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG4ZMNFVJlRS"
      },
      "outputs": [],
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBWg12KRJtEo"
      },
      "source": [
        "#Imprimindo alguns tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YA2QMjXJwE2",
        "outputId": "bd968d95-88b6-4e35-884e-cdd84e7a6805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['in', 'this', 'that', 'was', 'as', 'for', 'movie', 'with', 'but', 'film']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", vocab[100:110])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg0_SeTyKetY"
      },
      "source": [
        "#Definindo o tokenizer\n",
        "Vamos configurar o tokenizer com os vocabulários treinados anteriormente. Vamos definir um tamanho máximo para que todas sequências fiquem com o mesmo tamanho, se o tamanho da sequência for menor que o especificado. Se não, a sequência é truncada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pDss31SK8SS"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    lowercase=False,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwXx-I09K-mk"
      },
      "source": [
        "Tokenizando um exemplo do dataset para verificar se o texto foi tokenizado corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1zMZBy9LIjY",
        "outputId": "856f7354-f650-40a2-8153-20f29a0f828b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase:  tf.Tensor(b'this picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq. it paints a picture so unredeemable that i can\\'t help but wonder about it\\'s legitimacy and bias. also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd. to me the subject matter seemed confused, it only cared about portraying the military in a bad light, as a) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the v.a. this is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. i felt that \"the war tapes\" and \"blood of my brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. f-', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor(\n",
            "[  101   532   564   184    96    58 13296    13    99     8    58   316\n",
            "   104   165   104    93  9712  3634    95    93   300  3231    50 12058\n",
            "   120   125   225   380    97    57  2058   250   100  5075    15    99\n",
            "  7850    40   532   126  2929  2418  2300 10410   102    48   140     8\n",
            "    59   434   108   689   133    99     8    58  4016  8028 13308    94\n",
            "  8514    15   170    99   564    96   482  2089   127   203   133    93\n",
            "  4679  7293    95   351  4939    96    93   667    95  3916   553   100\n",
            "    93  1801   105    55  1136   244    15    96   159    93   965   642\n",
            "   564  1658    13    99   153  3935   133  2473    93  1398   100    40\n",
            "   165   732    13   104    40    10   124 14151 13368   102  1217   426\n",
            "  1255    96   560  2074  2798  1830  9944   173   962  2276    94    41\n",
            "    10   124  8426   102   378   355   436    94  1169    93  2498    95\n",
            "    99     8    58  1445   183  4276 10675   185    96    93  6266  8489\n",
            "   809    41  2172  6501 10725    95    93    61    15    40    15   101\n",
            "    97    40  7699  4073    13   108   525   216  3251   105   159    13\n",
            "   316   128    40   106   100    94    95   516    15    48   525   102\n",
            "     3    93   422  6152     3    94     3   621    95   149   662     3\n",
            "   160   163   141  1404    94   373    93   599  2689   138  8377    95\n",
            "   155   298   341   162   117  3877   209    93   522   107    93   109\n",
            "  1293  8797    15    45    14     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(512,), dtype=int32)\n",
            "Texto recuperado após a destokenização:  tf.Tensor(b'this picture seemed way to slanted , it \\' s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq . it paints a picture so unredeemable that i can \\' t help but wonder about it \\' s legitimacy and bias . also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd . to me the subject matter seemed confused , it only cared about portraying the military in a bad light , as a ) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b ) an organization that once having used and spent the bodies of it \\' s soldiers then discards them to the despotic bureacracy of the v . a . this is a legitimate argument , but felt off topic for me , almost like a movie in and of itself . i felt that \" the war tapes \" and \" blood of my brother \" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint . f - [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Frase: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Texto recuperado após a destokenização: \", tokenizer.detokenize(input_tokens_ex))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjI418Y1LSp0"
      },
      "source": [
        "#Formatando o dataset\n",
        "Aqui formataremos o dataset para a forma com a qual alimentaremos os modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceCq_8pDLrNW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({\"input_ids\": sentence}, label)\n",
        "\n",
        "\n",
        "def make_dataset(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvlr9KV0Ltfl"
      },
      "source": [
        "#Construindo o modelo\n",
        "Precisamos de uma camada embedding, uma camada que mapeia todos os tokens do imput em um vetor. Essa camada pode ser inicializada aleatoriamente. Também precisamos de uma camada embedding posicional, que codifica a ordem das palavras na sequência. O KerasNLP tem uma camada \"keras_nlp.layers.TokenAndPositionEmbedding\" que faz tudo isso para nós."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWcSAhfTLtI0"
      },
      "outputs": [],
      "source": [
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NijLI3I8MZ11"
      },
      "source": [
        "#Treinando o modelo\n",
        "Vamos usar a acurácia para monitorar o progresso do treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wSwiVLuMh8Z",
        "outputId": "a9f2a2d2-73bc-4780-94a3-6789a90d010e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"fnet_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 128)        1985536   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " f_net_encoder (FNetEncoder)  (None, None, 128)        132224    \n",
            "                                                                 \n",
            " f_net_encoder_1 (FNetEncode  (None, None, 128)        132224    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_2 (FNetEncode  (None, None, 128)        132224    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,382,337\n",
            "Trainable params: 2,382,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 35s 81ms/step - loss: 0.5907 - accuracy: 0.6349 - val_loss: 0.3506 - val_accuracy: 0.8450\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 23s 75ms/step - loss: 0.3077 - accuracy: 0.8715 - val_loss: 0.3475 - val_accuracy: 0.8574\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 23s 75ms/step - loss: 0.1965 - accuracy: 0.9239 - val_loss: 0.3675 - val_accuracy: 0.8554\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f53183b1190>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "fnet_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "fnet_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXLQdU-1MrhM"
      },
      "source": [
        "Obtivemos uma acurácia de treino de 92,39% e uma acurácia de validação de 85,54%. O treinamento levou 81 segundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiBjNDKeqM3L"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-8CTdANdkw",
        "outputId": "aecc4fda-b427-406a-d357-bb9280dce85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 17s 27ms/step - loss: 0.3962 - accuracy: 0.8418\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.39619317650794983, 0.841759979724884]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3DCgtJdNJ81"
      },
      "source": [
        "#Comparando com o Transformer\n",
        "Aqui vamos comparar o modelo FNet com um modelo Transformer. Vamos manter todos os parâmetros iguais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKCbivb1NWVB",
        "outputId": "8215ddaa-4142-46d4-99d5-f073af0cccc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 128)        1985536   \n",
            " g_1 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, None, 128)        198272    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, None, 128)        198272    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_2 (Tran  (None, None, 128)        198272    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,580,481\n",
            "Trainable params: 2,580,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 49s 146ms/step - loss: 0.4569 - accuracy: 0.7595 - val_loss: 0.3010 - val_accuracy: 0.8764\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 46s 146ms/step - loss: 0.2103 - accuracy: 0.9200 - val_loss: 0.3211 - val_accuracy: 0.8760\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 45s 144ms/step - loss: 0.1659 - accuracy: 0.9380 - val_loss: 0.3901 - val_accuracy: 0.8730\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52b249b910>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_HEADS = 2\n",
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")\n",
        "\n",
        "\n",
        "transformer_classifier.summary()\n",
        "transformer_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K_t3e_DN-zo"
      },
      "source": [
        "Obtivemos uma acurácia de treino de 93,80% e uma acurácia de validação de 87,30%. O treinamento levou 140 segundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgx3E4mCpLy4"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvF35Mv8N9cM",
        "outputId": "eb204c5b-b877-494c-a010-f0c84df1399b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 22s 56ms/step - loss: 0.4792 - accuracy: 0.8436\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4792218804359436, 0.8435999751091003]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0TP5NEyPWIG"
      },
      "source": [
        "#Sequence Length Grande\n",
        "Aqui vamos implementar o Embedding A, com sequence length maior. No caso, 1024. \n",
        "\n",
        "\n",
        "**Todos os comentários feitos anteriormente servem para esta parte do trabalho também**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjdX-Z58PYBa"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 1024\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 128\n",
        "INTERMEDIATE_DIM = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfkGEEayPoD9",
        "outputId": "574c4664-4bbb-4591-da96-892913874765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1hAinZuPsGx"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7mGUoIBPtxQ",
        "outputId": "9622bb8f-bbac-47f9-ad67-978bc886b14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'an illegal immigrant resists the social support system causing dire consequences for many. well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. the feeling of being lost in the big city is effectively conveyed. the little person lost in the big society is something to which we can all relate, but i cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"to get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. how beautifully the opening scene leading to the expulsion of gino establishes the theme of moral ambiguity! note the way music introduces the characters as we are led inside giovanna's marriage. don't expect to find much here of the political life of italy in 1943. that's not what this is about. on the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. by the end of the film we there are moments antonioni-like landscape that has more to do with the inner life of the characters than with real places. this is one of my favorite visconti films.\"\n",
            "1\n",
            "b'\"hollywood hotel\" has relationships to many films like \"ella cinders\" and \"merton of the movies\" about someone winning a contest including a contract to make films in hollywood, only to find the road to stardom either paved with pitfalls or non-existent. in fact, as i was watching it tonight, on turner classic movies, i was considering whether or not the authors of the later musical classic \"singing in the rain\" may have taken some of their ideas from \"hollywood hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"hollywood hotel\" is a fascinating example of movie making in the 1930s. among the supporting players is louella parsons, playing herself (and, despite some negative comments i\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). she is not the only real person in the script. make-up specialist perc westmore briefly appears as himself to try to make one character resemble another.<br /><br />this film also was one of the first in the career of young mr. ronald reagan, playing a radio interviewer at a movie premiere. reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody dick powell is about to take over the microphone when it should be used with more important people.<br /><br />dick powell has won a hollywood contract in a contest, and is leaving his job as a saxophonist in benny goodman\\'s band. the beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to powell. they end up singing \"hooray for hollywood\". the interesting thing about this wonderful number is that a lyric has been left out on purpose. throughout the johnny mercer lyrics are references to such hollywood as max factor the make-up king, rin tin tin, and even a hint of tarzan. but the original song lyric referred to looking like tyrone power. obviously jack warner and his brothers were not going to advertise the leading man of 20th century fox, and the name donald duck was substituted. in any event the number showed the singers and instrumentalists of goodman\\'s orchestra at their best. so did a later five minute section of the film, where the band is rehearsing.<br /><br />powell leaves the band and his girl friend (frances langford) and goes to hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). he is met by allen joslyn, the publicist of the studio (the owner is grant mitchell). joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. he parks powell at a room at the hollywood hotel, which is also where the studio\\'s temperamental star (lola lane) lives with her father (hugh herbert), her sister (mabel todd), and her sensible if cynical assistant (glenda farrell). lane is like jean hagen in \"singing in the rain\", except her speaking voice is good. her version of \"dan lockwood\" is one \"alexander dupre\" (alan mowbray, scene stealing with ease several times). the only difference is that mowbray is not a nice guy like gene kelly was, and lane (when not wrapped up in her ego) is fully aware of it. having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. joslyn finds a double for her (lola\\'s real life sister rosemary lane), and rosemary is made up to play the star at the premiere and the follow-up party. but she attends with powell (joslyn wanting someone who doesn\\'t know the real lola). this leads to powell knocking down mowbray when the latter makes a pest of himself. but otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />the complications deal with lola coming back and slapping powell in the face, after mowbray complains he was attacked by powell (\"and his gang of hoodlums\"). powell\\'s contract is bought out. working with photographer turned agent ted healey (actually not too bad in this film - he even tries to do a jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered edgar kennedy (the number of broken dishes and singing customers in the restaurant give edgar plenty of time to do his slow burns with gusto). eventually powell gets a \"break\" by being hired to be dupre\\'s singing voice in a rip-off of \"gone with the wind\". this leads to the final section of the film, when rosemary lane, herbert, and healey help give powell his chance to show it\\'s his voice, not mowbrays.<br /><br />it\\'s quite a cute and appealing film even now. the worst aspects are due to it\\'s time. several jokes concerning african-americans are no longer tolerable (while trying to photograph powell as he arrives in hollywood, healey accidentally photographs a porter, and mentions to joslyn to watch out, powell photographs too darkly - get the point?). also a bit with curt bois as a fashion designer for lola lane, who is (shall we say) too high strung is not very tolerable either. herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. and an incident where healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in december 1937. but most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7XAIbDdPvla"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    bert_vocab_args = dict(\n",
        "        # Tamanho do vocabulário de destino\n",
        "        vocab_size=vocab_size,\n",
        "        # Tokens reservados que devem ser incluídos no vocabulário \n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Argumentos para `text.BertTokenizer`\n",
        "        bert_tokenizer_params={\"lower_case\": True},\n",
        "    )\n",
        "\n",
        "    # Extrai amostras de texto (remove os rótulos).\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n",
        "    )\n",
        "    return vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTZjsioUPxCj"
      },
      "outputs": [],
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OeaY95JP0ox",
        "outputId": "817db2d4-c0e8-4329-91fe-afd90aa44d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['in', 'this', 'that', 'was', 'as', 'for', 'movie', 'with', 'but', 'film']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", vocab[100:110])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEQ-7JRmP1hw"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    lowercase=False,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUpDxlzP2gG",
        "outputId": "1fd3fa91-f2a6-42b2-8f94-8afae4672c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase:  tf.Tensor(b'this picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq. it paints a picture so unredeemable that i can\\'t help but wonder about it\\'s legitimacy and bias. also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd. to me the subject matter seemed confused, it only cared about portraying the military in a bad light, as a) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the v.a. this is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. i felt that \"the war tapes\" and \"blood of my brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. f-', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor([101 532 564 ...   0   0   0], shape=(1024,), dtype=int32)\n",
            "Texto recuperado após a destokenização:  tf.Tensor(b'this picture seemed way to slanted , it \\' s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq . it paints a picture so unredeemable that i can \\' t help but wonder about it \\' s legitimacy and bias . also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd . to me the subject matter seemed confused , it only cared about portraying the military in a bad light , as a ) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b ) an organization that once having used and spent the bodies of it \\' s soldiers then discards them to the despotic bureacracy of the v . a . this is a legitimate argument , but felt off topic for me , almost like a movie in and of itself . i felt that \" the war tapes \" and \" blood of my brother \" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint . f - [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Frase: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Texto recuperado após a destokenização: \", tokenizer.detokenize(input_tokens_ex))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiFUi5myP3ZU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({\"input_ids\": sentence}, label)\n",
        "\n",
        "\n",
        "def make_dataset(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jglOI6viP4qc"
      },
      "outputs": [],
      "source": [
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04xTAbiTP5se",
        "outputId": "dbf40356-e5cc-47dc-cb6a-f5df415c38d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"fnet_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 128)        2051072   \n",
            " g_2 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " f_net_encoder_3 (FNetEncode  (None, None, 128)        132224    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_4 (FNetEncode  (None, None, 128)        132224    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_5 (FNetEncode  (None, None, 128)        132224    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,447,873\n",
            "Trainable params: 2,447,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 53s 144ms/step - loss: 0.6093 - accuracy: 0.6271 - val_loss: 0.4258 - val_accuracy: 0.8084\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 44s 142ms/step - loss: 0.3589 - accuracy: 0.8439 - val_loss: 0.4658 - val_accuracy: 0.7908\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 44s 142ms/step - loss: 0.2454 - accuracy: 0.9017 - val_loss: 0.3858 - val_accuracy: 0.8430\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f529b80e790>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "fnet_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "fnet_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPy_VRZHTwTm"
      },
      "source": [
        "Obtivemos uma acurácia de treino de 90,17% e uma acurácia de validação de 84,30%. O treinamento levou 141 segundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcg40T4BpbE1"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyhIxetIP7UG",
        "outputId": "e721562f-5aa4-4d9a-a80b-e54c080fed4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 25s 49ms/step - loss: 0.4131 - accuracy: 0.8340\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.41311198472976685, 0.8340399861335754]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L1t1Drmpgbn"
      },
      "source": [
        "#Comparando com o Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty2XIuNzP8JB",
        "outputId": "eea09b10-2092-49d0-917f-c0eb803073a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 128)        2051072   \n",
            " g_3 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder_3 (Tran  (None, None, 128)        198272    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_4 (Tran  (None, None, 128)        198272    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_5 (Tran  (None, None, 128)        198272    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,646,017\n",
            "Trainable params: 2,646,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 127s 397ms/step - loss: 0.4619 - accuracy: 0.7634 - val_loss: 0.2843 - val_accuracy: 0.8870\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 125s 400ms/step - loss: 0.2128 - accuracy: 0.9196 - val_loss: 0.2881 - val_accuracy: 0.8900\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 126s 402ms/step - loss: 0.1730 - accuracy: 0.9334 - val_loss: 0.3250 - val_accuracy: 0.8880\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f529b962310>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_HEADS = 2\n",
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")\n",
        "\n",
        "\n",
        "transformer_classifier.summary()\n",
        "transformer_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31yNm1LLT5TW"
      },
      "source": [
        "Obtivemos uma acurácia de treino de 93,34% e uma acurácia de validação de 88,80%. O treinamento levou 378 segundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBgymtJipoGR"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37I60Jd9P9Oi",
        "outputId": "cb7b990e-e6b9-4ba1-ba59-badddeecb93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 62s 159ms/step - loss: 0.3782 - accuracy: 0.8706\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.37821200489997864, 0.8705999851226807]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfYF6UZNjSUH"
      },
      "source": [
        "# EMBEDDING B\n",
        "A Embedding B tem um tamanho maior que a anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JckRlKeNj3zZ"
      },
      "source": [
        "# Sequence Lenght Pequeno\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8S_fUX6jYrH"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 512\n",
        "INTERMEDIATE_DIM = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utifSkfGjhem",
        "outputId": "29e10d37-71db-4eb4-9a19-ae81ac890a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaCShjEYjs9u"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjdLyBnOjxK2",
        "outputId": "a543571a-068f-4d1f-daad-b69d0e3d41f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'an illegal immigrant resists the social support system causing dire consequences for many. well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. the feeling of being lost in the big city is effectively conveyed. the little person lost in the big society is something to which we can all relate, but i cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"to get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. how beautifully the opening scene leading to the expulsion of gino establishes the theme of moral ambiguity! note the way music introduces the characters as we are led inside giovanna's marriage. don't expect to find much here of the political life of italy in 1943. that's not what this is about. on the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. by the end of the film we there are moments antonioni-like landscape that has more to do with the inner life of the characters than with real places. this is one of my favorite visconti films.\"\n",
            "1\n",
            "b'\"hollywood hotel\" has relationships to many films like \"ella cinders\" and \"merton of the movies\" about someone winning a contest including a contract to make films in hollywood, only to find the road to stardom either paved with pitfalls or non-existent. in fact, as i was watching it tonight, on turner classic movies, i was considering whether or not the authors of the later musical classic \"singing in the rain\" may have taken some of their ideas from \"hollywood hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"hollywood hotel\" is a fascinating example of movie making in the 1930s. among the supporting players is louella parsons, playing herself (and, despite some negative comments i\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). she is not the only real person in the script. make-up specialist perc westmore briefly appears as himself to try to make one character resemble another.<br /><br />this film also was one of the first in the career of young mr. ronald reagan, playing a radio interviewer at a movie premiere. reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody dick powell is about to take over the microphone when it should be used with more important people.<br /><br />dick powell has won a hollywood contract in a contest, and is leaving his job as a saxophonist in benny goodman\\'s band. the beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to powell. they end up singing \"hooray for hollywood\". the interesting thing about this wonderful number is that a lyric has been left out on purpose. throughout the johnny mercer lyrics are references to such hollywood as max factor the make-up king, rin tin tin, and even a hint of tarzan. but the original song lyric referred to looking like tyrone power. obviously jack warner and his brothers were not going to advertise the leading man of 20th century fox, and the name donald duck was substituted. in any event the number showed the singers and instrumentalists of goodman\\'s orchestra at their best. so did a later five minute section of the film, where the band is rehearsing.<br /><br />powell leaves the band and his girl friend (frances langford) and goes to hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). he is met by allen joslyn, the publicist of the studio (the owner is grant mitchell). joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. he parks powell at a room at the hollywood hotel, which is also where the studio\\'s temperamental star (lola lane) lives with her father (hugh herbert), her sister (mabel todd), and her sensible if cynical assistant (glenda farrell). lane is like jean hagen in \"singing in the rain\", except her speaking voice is good. her version of \"dan lockwood\" is one \"alexander dupre\" (alan mowbray, scene stealing with ease several times). the only difference is that mowbray is not a nice guy like gene kelly was, and lane (when not wrapped up in her ego) is fully aware of it. having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. joslyn finds a double for her (lola\\'s real life sister rosemary lane), and rosemary is made up to play the star at the premiere and the follow-up party. but she attends with powell (joslyn wanting someone who doesn\\'t know the real lola). this leads to powell knocking down mowbray when the latter makes a pest of himself. but otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />the complications deal with lola coming back and slapping powell in the face, after mowbray complains he was attacked by powell (\"and his gang of hoodlums\"). powell\\'s contract is bought out. working with photographer turned agent ted healey (actually not too bad in this film - he even tries to do a jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered edgar kennedy (the number of broken dishes and singing customers in the restaurant give edgar plenty of time to do his slow burns with gusto). eventually powell gets a \"break\" by being hired to be dupre\\'s singing voice in a rip-off of \"gone with the wind\". this leads to the final section of the film, when rosemary lane, herbert, and healey help give powell his chance to show it\\'s his voice, not mowbrays.<br /><br />it\\'s quite a cute and appealing film even now. the worst aspects are due to it\\'s time. several jokes concerning african-americans are no longer tolerable (while trying to photograph powell as he arrives in hollywood, healey accidentally photographs a porter, and mentions to joslyn to watch out, powell photographs too darkly - get the point?). also a bit with curt bois as a fashion designer for lola lane, who is (shall we say) too high strung is not very tolerable either. herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. and an incident where healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in december 1937. but most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDOvo6cWj15i"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    bert_vocab_args = dict(\n",
        "        # Tamanho do vocabulário de destino\n",
        "        vocab_size=vocab_size,\n",
        "        # Tokens reservados que devem ser incluídos no vocabulário \n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Argumentos para `text.BertTokenizer`\n",
        "        bert_tokenizer_params={\"lower_case\": True},\n",
        "    )\n",
        "\n",
        "    # Extrai amostras de texto (remove os rótulos).\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n",
        "    )\n",
        "    return vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4vfKdrYkMR7"
      },
      "outputs": [],
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkw8rP9RkPoT",
        "outputId": "edebd627-9713-4b04-d9da-88f456f2b7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['in', 'this', 'that', 'was', 'as', 'for', 'movie', 'with', 'but', 'film']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", vocab[100:110])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_G7skfxkVIm"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    lowercase=False,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bn3MxRIkZC-",
        "outputId": "8cc922ed-ec94-4478-e37a-9a6189a1da38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase:  tf.Tensor(b'this picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq. it paints a picture so unredeemable that i can\\'t help but wonder about it\\'s legitimacy and bias. also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd. to me the subject matter seemed confused, it only cared about portraying the military in a bad light, as a) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the v.a. this is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. i felt that \"the war tapes\" and \"blood of my brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. f-', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor(\n",
            "[  101   532   564   184    96    58 13296    13    99     8    58   316\n",
            "   104   165   104    93  9712  3634    95    93   300  3231    50 12058\n",
            "   120   125   225   380    97    57  2058   250   100  5075    15    99\n",
            "  7850    40   532   126  2929  2418  2300 10410   102    48   140     8\n",
            "    59   434   108   689   133    99     8    58  4016  8028 13308    94\n",
            "  8514    15   170    99   564    96   482  2089   127   203   133    93\n",
            "  4679  7293    95   351  4939    96    93   667    95  3916   553   100\n",
            "    93  1801   105    55  1136   244    15    96   159    93   965   642\n",
            "   564  1658    13    99   153  3935   133  2473    93  1398   100    40\n",
            "   165   732    13   104    40    10   124 14151 13368   102  1217   426\n",
            "  1255    96   560  2074  2798  1830  9944   173   962  2276    94    41\n",
            "    10   124  8426   102   378   355   436    94  1169    93  2498    95\n",
            "    99     8    58  1445   183  4276 10675   185    96    93  6266  8489\n",
            "   809    41  2172  6501 10725    95    93    61    15    40    15   101\n",
            "    97    40  7699  4073    13   108   525   216  3251   105   159    13\n",
            "   316   128    40   106   100    94    95   516    15    48   525   102\n",
            "     3    93   422  6152     3    94     3   621    95   149   662     3\n",
            "   160   163   141  1404    94   373    93   599  2689   138  8377    95\n",
            "   155   298   341   162   117  3877   209    93   522   107    93   109\n",
            "  1293  8797    15    45    14     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(512,), dtype=int32)\n",
            "Texto recuperado após a destokenização:  tf.Tensor(b'this picture seemed way to slanted , it \\' s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq . it paints a picture so unredeemable that i can \\' t help but wonder about it \\' s legitimacy and bias . also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd . to me the subject matter seemed confused , it only cared about portraying the military in a bad light , as a ) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b ) an organization that once having used and spent the bodies of it \\' s soldiers then discards them to the despotic bureacracy of the v . a . this is a legitimate argument , but felt off topic for me , almost like a movie in and of itself . i felt that \" the war tapes \" and \" blood of my brother \" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint . f - [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Frase: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Texto recuperado após a destokenização: \", tokenizer.detokenize(input_tokens_ex))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCxnrnP1kd6d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({\"input_ids\": sentence}, label)\n",
        "\n",
        "\n",
        "def make_dataset(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K56N8SfkhhD"
      },
      "outputs": [],
      "source": [
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If_ZtxASkkuM",
        "outputId": "c4e1268c-5e65-4c7c-c072-7560508c4270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"fnet_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 512)        7942144   \n",
            " g_4 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " f_net_encoder_6 (FNetEncode  (None, None, 512)        1052160   \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_7 (FNetEncode  (None, None, 512)        1052160   \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_8 (FNetEncode  (None, None, 512)        1052160   \n",
            " r)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 512)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,099,137\n",
            "Trainable params: 11,099,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 113s 326ms/step - loss: 0.6130 - accuracy: 0.6607 - val_loss: 0.4121 - val_accuracy: 0.8142\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 103s 331ms/step - loss: 0.3614 - accuracy: 0.8410 - val_loss: 0.3572 - val_accuracy: 0.8436\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 105s 335ms/step - loss: 0.2629 - accuracy: 0.8931 - val_loss: 0.4050 - val_accuracy: 0.8376\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f529964d640>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "fnet_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "fnet_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cywERUSfpytz"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0u_uNqzkxiO",
        "outputId": "7b928e9f-c6c3-4589-b487-f6c57bd0359d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 51s 110ms/step - loss: 0.3989 - accuracy: 0.8389\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.39893269538879395, 0.8388800024986267]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j697vyfgp0u5"
      },
      "source": [
        "#Comparando com o Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hveJkvWk566",
        "outputId": "c81e6f8b-1e88-4ac3-db00-9fd5e11cb3b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 512)        7942144   \n",
            " g_5 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder_6 (Tran  (None, None, 512)        2102784   \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_7 (Tran  (None, None, 512)        2102784   \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_8 (Tran  (None, None, 512)        2102784   \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_5   (None, 512)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,251,009\n",
            "Trainable params: 14,251,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 196s 614ms/step - loss: 0.7710 - accuracy: 0.5045 - val_loss: 0.6963 - val_accuracy: 0.5076\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 192s 612ms/step - loss: 0.7017 - accuracy: 0.4990 - val_loss: 0.6964 - val_accuracy: 0.4924\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 192s 613ms/step - loss: 0.6994 - accuracy: 0.4947 - val_loss: 0.6955 - val_accuracy: 0.4924\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f529a61d3d0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_HEADS = 2\n",
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")\n",
        "\n",
        "\n",
        "transformer_classifier.summary()\n",
        "transformer_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJBw7-DJqUko"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oeh8_YPk9s-",
        "outputId": "8d1485a5-300a-429a-bd9d-809c0863a6a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 81s 207ms/step - loss: 0.6947 - accuracy: 0.5000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6946806907653809, 0.5]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaPvlBMM9uqZ"
      },
      "source": [
        "# Sequence Lenght Grande"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ClYsy79uqa"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 1024\n",
        "VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 512\n",
        "INTERMEDIATE_DIM = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYdybUKL9uqa",
        "outputId": "be96a611-cfd3-41b3-813e-36277a5e258c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W4PN1pb9uqa"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.strings.lower(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.strings.lower(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luSdbv8q9uqa",
        "outputId": "c1121670-1bd4-4454-bcd1-289ec78179ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'an illegal immigrant resists the social support system causing dire consequences for many. well filmed and acted even though the story is a bit forced, yet the slow pacing really sets off the conclusion. the feeling of being lost in the big city is effectively conveyed. the little person lost in the big society is something to which we can all relate, but i cannot endorse going out of your way to see this movie.'\n",
            "0\n",
            "b\"to get in touch with the beauty of this film pay close attention to the sound track, not only the music, but the way all sounds help to weave the imagery. how beautifully the opening scene leading to the expulsion of gino establishes the theme of moral ambiguity! note the way music introduces the characters as we are led inside giovanna's marriage. don't expect to find much here of the political life of italy in 1943. that's not what this is about. on the other hand, if you are susceptible to the music of images and sounds, you will be led into a word that reaches beyond neo-realism. by the end of the film we there are moments antonioni-like landscape that has more to do with the inner life of the characters than with real places. this is one of my favorite visconti films.\"\n",
            "1\n",
            "b'\"hollywood hotel\" has relationships to many films like \"ella cinders\" and \"merton of the movies\" about someone winning a contest including a contract to make films in hollywood, only to find the road to stardom either paved with pitfalls or non-existent. in fact, as i was watching it tonight, on turner classic movies, i was considering whether or not the authors of the later musical classic \"singing in the rain\" may have taken some of their ideas from \"hollywood hotel\", most notably a temperamental leading lady star in a movie studio and a conclusion concerning one person singing a film score while another person got the credit by mouthing along on screen.<br /><br />\"hollywood hotel\" is a fascinating example of movie making in the 1930s. among the supporting players is louella parsons, playing herself (and, despite some negative comments i\\'ve seen, she has a very ingratiating personality on screen and a natural command of her lines). she is not the only real person in the script. make-up specialist perc westmore briefly appears as himself to try to make one character resemble another.<br /><br />this film also was one of the first in the career of young mr. ronald reagan, playing a radio interviewer at a movie premiere. reagan actually does quite nicely in his brief scenes - particularly when he realizes that nobody dick powell is about to take over the microphone when it should be used with more important people.<br /><br />dick powell has won a hollywood contract in a contest, and is leaving his job as a saxophonist in benny goodman\\'s band. the beginning of this film, by the way, is quite impressive, as the band drives in a parade of trucks to give a proper goodbye to powell. they end up singing \"hooray for hollywood\". the interesting thing about this wonderful number is that a lyric has been left out on purpose. throughout the johnny mercer lyrics are references to such hollywood as max factor the make-up king, rin tin tin, and even a hint of tarzan. but the original song lyric referred to looking like tyrone power. obviously jack warner and his brothers were not going to advertise the leading man of 20th century fox, and the name donald duck was substituted. in any event the number showed the singers and instrumentalists of goodman\\'s orchestra at their best. so did a later five minute section of the film, where the band is rehearsing.<br /><br />powell leaves the band and his girl friend (frances langford) and goes to hollywood, only to find he is a contract player (most likely for musicals involving saxophonists). he is met by allen joslyn, the publicist of the studio (the owner is grant mitchell). joslyn is not a bad fellow, but he is busy and he tends to slough off people unless it is necessary to speak to them. he parks powell at a room at the hollywood hotel, which is also where the studio\\'s temperamental star (lola lane) lives with her father (hugh herbert), her sister (mabel todd), and her sensible if cynical assistant (glenda farrell). lane is like jean hagen in \"singing in the rain\", except her speaking voice is good. her version of \"dan lockwood\" is one \"alexander dupre\" (alan mowbray, scene stealing with ease several times). the only difference is that mowbray is not a nice guy like gene kelly was, and lane (when not wrapped up in her ego) is fully aware of it. having a fit on being by-passed for an out-of-the ordinary role she wanted, she refuses to attend the premiere of her latest film. joslyn finds a double for her (lola\\'s real life sister rosemary lane), and rosemary is made up to play the star at the premiere and the follow-up party. but she attends with powell (joslyn wanting someone who doesn\\'t know the real lola). this leads to powell knocking down mowbray when the latter makes a pest of himself. but otherwise the evening is a success, and when the two are together they start finding each other attractive.<br /><br />the complications deal with lola coming back and slapping powell in the face, after mowbray complains he was attacked by powell (\"and his gang of hoodlums\"). powell\\'s contract is bought out. working with photographer turned agent ted healey (actually not too bad in this film - he even tries to do a jolson imitation at one point), the two try to find work, ending up as employees at a hamburger stand run by bad tempered edgar kennedy (the number of broken dishes and singing customers in the restaurant give edgar plenty of time to do his slow burns with gusto). eventually powell gets a \"break\" by being hired to be dupre\\'s singing voice in a rip-off of \"gone with the wind\". this leads to the final section of the film, when rosemary lane, herbert, and healey help give powell his chance to show it\\'s his voice, not mowbrays.<br /><br />it\\'s quite a cute and appealing film even now. the worst aspects are due to it\\'s time. several jokes concerning african-americans are no longer tolerable (while trying to photograph powell as he arrives in hollywood, healey accidentally photographs a porter, and mentions to joslyn to watch out, powell photographs too darkly - get the point?). also a bit with curt bois as a fashion designer for lola lane, who is (shall we say) too high strung is not very tolerable either. herbert\\'s \"hoo-hoo\"ing is a bit much (too much of the time) but it was really popular in 1937. and an incident where healey nearly gets into a brawl at the premiere (this was one of his last films) reminds people of the tragic, still mysterious end of the comedian in december 1937. but most of the film is quite good, and won\\'t disappoint the viewer in 2008.'\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(3):\n",
        "        print(text_batch.numpy()[i])\n",
        "        print(label_batch.numpy()[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKimo9kr9uqb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_word_piece(ds, vocab_size, reserved_tokens):\n",
        "    bert_vocab_args = dict(\n",
        "        # Tamanho do vocabulário de destino\n",
        "        vocab_size=vocab_size,\n",
        "        # Tokens reservados que devem ser incluídos no vocabulário \n",
        "        reserved_tokens=reserved_tokens,\n",
        "        # Argumentos para `text.BertTokenizer`\n",
        "        bert_tokenizer_params={\"lower_case\": True},\n",
        "    )\n",
        "\n",
        "    # Extrai amostras de texto (remove os rótulos).\n",
        "    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n",
        "    vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "        word_piece_ds.batch(1000).prefetch(2), **bert_vocab_args\n",
        "    )\n",
        "    return vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3H4mIi39uqb"
      },
      "outputs": [],
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\"]\n",
        "train_sentences = [element[0] for element in train_ds]\n",
        "vocab = train_word_piece(train_ds, VOCAB_SIZE, reserved_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up2zpSxM9uqb",
        "outputId": "e1225083-2f83-4898-ff70-1ff4b1ec4c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['in', 'this', 'that', 'was', 'as', 'for', 'movie', 'with', 'but', 'film']\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokens: \", vocab[100:110])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGc3AY_89uqb"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    lowercase=False,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiI4Tzn49uqb",
        "outputId": "1c590d37-4e8b-4798-cfff-1104f7cdb4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frase:  tf.Tensor(b'this picture seemed way to slanted, it\\'s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq. it paints a picture so unredeemable that i can\\'t help but wonder about it\\'s legitimacy and bias. also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd. to me the subject matter seemed confused, it only cared about portraying the military in a bad light, as a) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b) an organization that once having used and spent the bodies of it\\'s soldiers then discards them to the despotic bureacracy of the v.a. this is a legitimate argument, but felt off topic for me, almost like a movie in and of itself. i felt that \"the war tapes\" and \"blood of my brother\" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint. f-', shape=(), dtype=string)\n",
            "Tokens:  tf.Tensor([101 532 564 ...   0   0   0], shape=(1024,), dtype=int32)\n",
            "Texto recuperado após a destokenização:  tf.Tensor(b'this picture seemed way to slanted , it \\' s almost as bad as the drum beating of the right wing kooks who say everything is rosy in iraq . it paints a picture so unredeemable that i can \\' t help but wonder about it \\' s legitimacy and bias . also it seemed to meander from being about the murderous carnage of our troops to the lack of health care in the states for ptsd . to me the subject matter seemed confused , it only cared about portraying the military in a bad light , as a ) an organzation that uses mind control to turn ordinary peace loving civilians into baby killers and b ) an organization that once having used and spent the bodies of it \\' s soldiers then discards them to the despotic bureacracy of the v . a . this is a legitimate argument , but felt off topic for me , almost like a movie in and of itself . i felt that \" the war tapes \" and \" blood of my brother \" were much more fair and let the viewer draw some conclusions of their own rather than be beaten over the head with the film makers viewpoint . f - [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "input_sentence_ex = train_ds.take(1).get_single_element()[0][0]\n",
        "input_tokens_ex = tokenizer(input_sentence_ex)\n",
        "\n",
        "print(\"Frase: \", input_sentence_ex)\n",
        "print(\"Tokens: \", input_tokens_ex)\n",
        "print(\"Texto recuperado após a destokenização: \", tokenizer.detokenize(input_tokens_ex))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd-3wtVf9uqb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_dataset(sentence, label):\n",
        "    sentence = tokenizer(sentence)\n",
        "    return ({\"input_ids\": sentence}, label)\n",
        "\n",
        "\n",
        "def make_dataset(dataset):\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(512).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_ds)\n",
        "val_ds = make_dataset(val_ds)\n",
        "test_ds = make_dataset(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbyqa3_W9uqb"
      },
      "outputs": [],
      "source": [
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "x = keras_nlp.layers.FNetEncoder(intermediate_dim=INTERMEDIATE_DIM)(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "fnet_classifier = keras.Model(input_ids, outputs, name=\"fnet_classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8403RNt9uqb",
        "outputId": "feda9ae2-b439-4d62-cd0a-414400e06709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"fnet_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 512)        8204288   \n",
            " g_6 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " f_net_encoder_9 (FNetEncode  (None, None, 512)        1052160   \n",
            " r)                                                              \n",
            "                                                                 \n",
            " f_net_encoder_10 (FNetEncod  (None, None, 512)        1052160   \n",
            " er)                                                             \n",
            "                                                                 \n",
            " f_net_encoder_11 (FNetEncod  (None, None, 512)        1052160   \n",
            " er)                                                             \n",
            "                                                                 \n",
            " global_average_pooling1d_6   (None, 512)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,361,281\n",
            "Trainable params: 11,361,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 212s 653ms/step - loss: 0.5892 - accuracy: 0.6767 - val_loss: 0.4924 - val_accuracy: 0.7540\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 209s 667ms/step - loss: 0.3667 - accuracy: 0.8386 - val_loss: 0.4133 - val_accuracy: 0.8234\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 209s 669ms/step - loss: 0.2723 - accuracy: 0.8856 - val_loss: 0.3714 - val_accuracy: 0.8424\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f529a03db80>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.summary()\n",
        "fnet_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "fnet_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4m_HwCPqD1z"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-jgJ9fz9uqc",
        "outputId": "f4a28ac8-8717-4231-9a65-f586190efdc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 91s 213ms/step - loss: 0.3777 - accuracy: 0.8372\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.37769144773483276, 0.8371999859809875]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnet_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2VqtApFqFth"
      },
      "source": [
        "#Comparando com o Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vz2eCYp9uqc",
        "outputId": "efbf5e06-4adf-4b97-a649-b046a07ab429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_ids (InputLayer)      [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 512)        8204288   \n",
            " g_7 (TokenAndPositionEmbedd                                     \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_encoder_9 (Tran  (None, None, 512)        2102784   \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " transformer_encoder_10 (Tra  (None, None, 512)        2102784   \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " transformer_encoder_11 (Tra  (None, None, 512)        2102784   \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d_7   (None, 512)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,513,153\n",
            "Trainable params: 14,513,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "313/313 [==============================] - 455s 1s/step - loss: 0.7773 - accuracy: 0.4999 - val_loss: 0.6938 - val_accuracy: 0.4924\n",
            "Epoch 2/3\n",
            "313/313 [==============================] - 447s 1s/step - loss: 0.6859 - accuracy: 0.5350 - val_loss: 0.6931 - val_accuracy: 0.5076\n",
            "Epoch 3/3\n",
            "313/313 [==============================] - 447s 1s/step - loss: 0.7004 - accuracy: 0.4959 - val_loss: 0.6986 - val_accuracy: 0.5076\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5316afdeb0>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NUM_HEADS = 2\n",
        "input_ids = keras.Input(shape=(None,), dtype=\"int64\", name=\"input_ids\")\n",
        "\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(input_ids)\n",
        "\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "x = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "\n",
        "\n",
        "x = keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "transformer_classifier = keras.Model(input_ids, outputs, name=\"transformer_classifier\")\n",
        "\n",
        "\n",
        "transformer_classifier.summary()\n",
        "transformer_classifier.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer_classifier.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmZc2YIVqZYy"
      },
      "source": [
        "#Calculando a precisão do teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV8GZ1rD9uqc",
        "outputId": "7d10062c-067a-4cea-e118-84f95916ed63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 195s 500ms/step - loss: 0.7004 - accuracy: 0.5002\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7003594636917114, 0.5001599788665771]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_classifier.evaluate(test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UeycBPLO4Ce"
      },
      "source": [
        "#***CONCLUSÃO***\n",
        "\n",
        "**PARA A EMBEDDING A**\n",
        "\n",
        "*Sequence length pequena*\n",
        "\n",
        "Analisando ambas arquiteturas, podemos ver que o FNet diminui muito o tempo de execução apenas perdendo um pouco da acurácia no geral.\n",
        "\n",
        "Podemos concluir que, no caso da Embedding A com sequence length pequena, a melhor arquitetura foi o FNet, já que seu tempo de execução é 1,7 vezes mais rápida com uma pequena diferença na acurácia geral (1,4%).\n",
        "\n",
        "*Sequence length grande*\n",
        "\n",
        "Analisando ambas as arquiteturas para uma sequence length maior, podemos observar que o tempo de execução do transformer foi muito maior que do fnet (378 segundos e 141 segundos, respectivamente), perdendo um pouco da acurácia.\n",
        "\n",
        "Podemos concluir que, no caso da Embedding A com sequence length grande, a melhor arquitetura foi o FNet também, já que seu tempo de execução é 2,6 vezes mais rápida que o transformer com uma pequena diferença na acurácia geral (3%).\n",
        "\n",
        "Comparando os sequence length grande e pequeno e as arquiteturas, podemos observar que quando o sequence length é grande, o FNet tem uma maior diferença de tempo em relação ao Transformer, porém uma perda maior na acurácia.\n",
        "\n",
        "**PARA A EMBEDDING B**\n",
        "\n",
        "*Sequence length pequena*\n",
        "\n",
        "Analisando ambas arquiteturas, podemos observar que o FNet tem um tempo de execução menor que o Transformer porém a acurácia no Transformer diminui quase pela metade (acurácia FNet: 89,31%; acurácia Transformer: 49,47%).\n",
        "\n",
        "Podemos concluir que a melhor arquitetura aqui também foi o FNet, já que tanto a acurácia quanto o tempo de execução foram melhores (acurácia maior e tempo menor).\n",
        "\n",
        "*Sequence length grande*\n",
        "\n",
        "Analisando ambas as arquiteturas para uma sequence length maior, podemos observar que o tempo de execução do transformer foi muito maior que do fnet (1349 segundos e 630 segundos, respectivamente), perdendo muito da acurácia (FNet teve uma acurácia de 88,56% enquanto o Transformer obteve uma acurácia de 50,76%).\n",
        "\n",
        "Podemos concluir que, no caso da Embedding B com sequence length grande, a melhor arquitetura foi o FNet também, já que seu tempo de execução é 1,8 vezes mais rápida que o transformer com uma grande diferença na acurácia geral (39,84%).\n",
        "\n",
        "# ***CONCLUSÃO GERAL***\n",
        "\n",
        "Em relação aos embeddings, quando aumentamos o tamanho o tempo de execução também aumenta consideravelmente e há uma perda de acurácia para ambos os casos.\n",
        "\n",
        "Por fim, podemos dizer que, comparando entre estas duas arquiteturas implementadas neste trabalho para o problema de classificação de texto, o modelo FNet é a melhor escolha, uma vez que se saiu melhor na maioria dos cenários quando levamos em conta acurácia em relação ao tempo de execução."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VBgymtJipoGR",
        "rfYF6UZNjSUH",
        "8UeycBPLO4Ce"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
