{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LudaveLuda/ProjetoIAClassificadordeTexto/blob/master/2023S1_AC2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOIU9SaeIAz-"
      },
      "source": [
        "# <center>Centro Universitário Facens<br/></center>\n",
        "<br/>\n",
        "<font size=\"4\"><center><b>Disciplina: Processamento de imagens</b></center></font>\n",
        "  \n",
        "<font size=\"3\"><center>Prof. Renato M. Silva</center></font>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "## <center>Avaliação Continuada 2 (AC2)</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjnpwC1300J_"
      },
      "source": [
        "----\n",
        "### <center>Nome e RA dos componentes do grupo</center>\n",
        "\n",
        "    \n",
        "| Nome     |      RA      | \n",
        "|:-        |:-------------:|\n",
        "|          |              | \n",
        "|          |              | \n",
        "|          |              | \n",
        "|          |              | \n",
        "|          |              | \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3zgb7L00J_"
      },
      "source": [
        "----\n",
        "### Instruções\n",
        "**1**. Siga boas práticas de programação:\n",
        "- dar nomes intuitivos para as variáveis\n",
        "- dar nomes intuitivos para as funções\n",
        "\n",
        "**2**. O trabalho pode ser feito em grupos de até 5 pessoas. Porém, todos os componentes devem ser da mesma turma de Processamento de Imagens. \n",
        " - Caso algum grupo contenha alguém de uma turma diferente, todo o grupo receberá nota zero.\n",
        " - Apenas uma pessoa do grupo deve submeter o trabalho. \n",
        " - Você deve submeter apenas o arquivo .ipynb.\n",
        "\n",
        "**3**. Em todos os exercícios, as imagens finais solicitadas devem estar no formato **uint8**.\n",
        "\n",
        "**4**. Cuidado com plágio. Se for detectado plágio entre grupos, a punição será dada para todos os componentes dos grupos envolvidos. \n",
        "\n",
        "**5**. Antes de submeter o notebook, certifique-se que não há erros de código. Uma forma de se certificar disso é usar a opção **\"Reiniciar Kernel e executar todas as células\"** do Jupyter ou a opção **\"Reiniciar e executar tudo\"** do Google Colab. \n",
        "\n",
        "**6**. A única biblioteca de processamento de imagens permitida neste trabalho é a **OpenCV**. Porém, alguns exercícios poderão limitar algumas funções dessa biblioteca que poderão ser usadas. \n",
        "\n",
        "**7**. Em todos os exercícios que pedirem para salvar a imagem resultante, tome cuidado de converter a imagem para BGR antes de salvá-la pois esse é o formato padrão da biblioteca OpenCV. Caso contrário, os canais de cores da imagem resultante ficarão trocados. \n",
        "\n",
        "**8**. Em todos os exercícios, caso o resultado seja uma ou mais imagens, você deve mostrá-las na tela. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taaWUs_z00KA"
      },
      "source": [
        "----\n",
        "## Exercício 1\n",
        "\n",
        "Implemente uma função que consiga fazer a detecção de movimentos em um vídeo. Ela deverá extrair os frames do vídeo e, para cada frame, deve calcular o **histograma** da imagem e compará-lo com os últimos histogramas calculados. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, simule um alarme interrompendo a função e retornando uma mensagem de alerta. Utilize uma função de comparação que julgar conveniente. \n",
        "- A diferença entre dois histogramas pode ser calculada por meio de medidas estatísticas, como média, desvio padrão, mediana, IQR, etc. \n",
        "\n",
        "Teste a função no vídeo *videos/cameraEscondida.mp4*.\n",
        "\n",
        "**Obs.** Neste exercício é permitido usar a biblioteca **imageio** ou qualquer para **extrair os frames** do vídeo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3efPcW200KA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTJkrn0Q00KB"
      },
      "source": [
        "----\n",
        "## Exercício 2\n",
        "\n",
        "\n",
        "Implemente um algoritmo que faça a combinação das imagens **figs/facensLogo.png** e **facensVistaAerea.webp** para gerar o resultado apresentado abaixo. Salve a imagem resultante na pasta **figsResultado** com o nome **ex02.png**\n",
        "\n",
        "Para atingir esse resultado, as únicas funções da biblioteca **OpencCV** que poderão ser aplicadas são: **warpAffine**, **getRotationMatrix2D**, **resize**, **cvtColor** e aquelas que sirvam para abrir ou salvar uma imagem. Todas as demais operações deverão ser implementadas por meio de operações matriciais, podendo ser aplicadas função da biblioteca **NumPy**. \n",
        "\n",
        "**Dicas**: \n",
        "- Divida a imagem **facensVistaAerea.webp** em quatro partes iguais. Depois disso, aplique rotação em cada uma das 4 partes.\n",
        "- Para remover o fundo da imagem **figs/facensLogo.png**, você pode usar a segmentação por limiarização. Depois disso, você pode rotacionar cada uma dos quatro quadrantes para conseguir atingir o efeito mostrado na imagem abaixo.\n",
        "- Você pode usar as operações de soma e de escalamento para ajudar a atingir a imagem alvo.\n",
        "\n",
        "<center>\n",
        "<div style=\"display:inline-block;\">\n",
        "    <div style=\"padding: 5px; float: left;\">\n",
        "        <img src=\"figsNotebook/facens1.jpg\" width=\"400\" height=\"400\" />\n",
        "    </div>\n",
        "</div> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnKy9fzZ00KB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2aqMmLH00KB"
      },
      "source": [
        "----\n",
        "## Exercicio 3\n",
        "\n",
        "Implemente uma função que receba uma imagem e retorne três imagens novas: uma contendo apenas os objetos com cor predominantemente vermelhas, outro com os objetos que possuem cor predominantemente verde e uma com os objetos com cor predominantemente azuis. Os demais objetos devem desaparecer da imagem resultante, transformando seus pixels para o valor 0. \n",
        "\n",
        "Para atingir o objetivo deste exercício é permitido usar apenas a biblioteca NumPy. As únicas funções da biblioteca OpenCV permitidas são a **cvtColor** e aquelas que abrem ou salvam uma imagem. \n",
        "\n",
        "Teste sua função passando como entrada a imagem **figs/objetos.png**. Salve as imagens resultantes na pasta \"**figsResultado**\" com os seguintes nomes: **ex03_objetosVermelhos.png**, **ex03_objetosVerdes.png** e **ex03_objetosAzuis.png**.\n",
        "\n",
        "Dicas: \n",
        "\n",
        " - Usando a biblioteca Numpy, é possível selecionar apenas os valores de uma determinada matriz que atendem a mais de uma restrição. Por exemplo, supondo que você queira transformar os valores de uma matriz que sejam maiores que 50 e menores que 100 para -1, você poderia aplicar a seguinte operação:\n",
        "\n",
        "```matriz[ (matriz>50) & (matriz<100) ] = -1 ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxfzHDM700KC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "9un21eOb00KC"
      },
      "source": [
        "----\n",
        "## Exercicio 4\n",
        "\n",
        "\n",
        "Faça uma função que desenhe um rosto. Essa função deve receber como parâmetro a cor do rosto, dos olhos, do nariz e da boca. \n",
        "\n",
        "A função deve funcionar para todas as cores primárias, secundárias e, também, preto e branco. No entanto, só é permitido criar os objetos que formam o rosto com as cores primárias. Para gerar objetos com preto, branco e cores secundárias, você deverá fazer operações aritméticas usando objetos gerados com as cores primárias. \n",
        "\n",
        "Por exemplo, supondo que essa função tenha recebido rosto=\"preto\", olhos=\"vermelho\", nariz=\"branco\", boca=\"verde\" como entrada, ela deveria produzir o rosto similar ao mostrado abaixo. \n",
        "\n",
        "-  Neste exercício é permitido usar apenas a biblioteca NumPy. As únicas funções da biblioteca OpenCV permitidas são a **cvtColor** e aquelas que abrem ou salvam uma imagem. \n",
        "\n",
        "- A imagem resultante não precisa ser igual a mostrada no exemplo. Pode exercer sua criatividade, desde que o rosto, olhos, boca e nariz sejam criados por meio de operações matriciais.\n",
        "\n",
        "- Teste sua função com três entradas diferentes e salve as imagens na pasta **figsResultado** com os nomes: ex04_rosto1.png, ex04_rosto2.png, ex04_rosto3.png\n",
        "\n",
        "\n",
        "<center>\n",
        "<div style=\"display:inline-block;\">\n",
        "    <div style=\"padding: 5px; float: left;\">\n",
        "        <img src=\"figsNotebook/rosto.png\" width=\"150\" height=\"150\" />\n",
        "    </div>\n",
        "</div> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yLl5rr700KC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN-5VV5R00KC"
      },
      "source": [
        "----\n",
        "## Exercicio 5\n",
        "\n",
        "Utilize operações morfológicas nas imagens **figs/manequim.png** e **figs/tabuleiro.jpg** para remover todos os pontos brancos. Por outro lado, use as operaçòes morfológicas para remover apenas os círculos menores da imagem **figs/circulos.tif**, deixando apenas os círculos maiores. \n",
        "\n",
        "\n",
        "Salve as imagens resultantes na pasta **figsResultado** com os nomes ex05_manequim.png, ex05_tabuleiro.png e ex05_circulos.png."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVhHTGpe00KD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ViWWZd00KD"
      },
      "source": [
        "----\n",
        "## Exercicio 6\n",
        "\n",
        "Aplique um filtro para borrar as extremidades da imagem **figs/vista.jpg** para que ela fique com o efeito mostrado na imagem abaixo. Salve a imagem resultante na pasta **figsResultado** com o nome **ex06_vista.png**\n",
        "\n",
        "<img src=\"figsNotebook/vista_blur.jpg\" width=\"500\" height=\"128\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGn62Kdm00KD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ovnr_cA00KD"
      },
      "source": [
        "----\n",
        "## Exercicio 7\n",
        "\n",
        "Sabe-se que as técnicas de filtragem podem ser usadas para eliminar ruídos. Porém, elas também podem perder detalhes da imagem. Uma forma de diminuir o problema da perda de detalhes é aplicar um realce na imagem após a filtragem. \n",
        "\n",
        "Sabe-se também que é possível aplicar realce combinando a imagem filtrada com a o resultado da sua detecção de bordas. \n",
        "\n",
        "Com base nas afirmações acima, aplique pelo menos dois filtros na imagem **figs/lena_noise.png** para diminuir o ruído. Depois, para aumentar o realce, faça uma operação aritmética de cada uma das imagens filtradas com o resultado da detecção de bordas por meio do operador de gradiente de Robinson (1977) e outras duas técnicas de detecção de bordas quaisquer. Salve as imagens resultantes na pasta **figsResultado** com os nomes: \"ex07_filtro1borda1.png\", \"ex07_filtro2borda1.png\", \"ex07_filtro1borda2.png\", \"ex07_filtro2borda2.png\"  \"ex07_filtro3borda1.png\", \"ex07_filtro3borda2.png\".\n",
        "\n",
        " - trate os tons de cinza inválidos usando a técnica de saturação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7g5XRTS00KD"
      },
      "source": [
        "----\n",
        "## Exercicio 8\n",
        "\n",
        "Sabe-se que as técnicas de filtragem podem ser usadas para eliminar ruídos. Porém, elas também podem perder detalhes da imagem. Uma forma de diminuir o problema da perda de detalhes é aplicar um realce na imagem após a filtragem. \n",
        "\n",
        "Repita os códigos que você fez no exercício anterior para filtragem da imagem **figs/lena_noise.png**. Use as duas imagens resultantes como entrada de duas funções. A primeira deve fazer o realce combinando as técnicas de top-hat e bottom-hat. A segunda deve fazer o realce usando a seginte equação:\n",
        "    \n",
        "\\$$g = \n",
        "\\begin{cases}\n",
        "f \\ominus b \\text{, } & \\text{ se } f - (f \\ominus b) <  ( f \\oplus b ) - f \\\\\n",
        "f \\oplus b\\text{, } & \\text{ caso contrário }\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Na equação acima,  $f \\ominus b$ é o resultado da operação de erosão no pixel $f$ usando o elemento estruturante $b$. Por outro lado, $f \\oplus b$ é o resultado da operação de dilatação no pixel $f$ usando o elemento estruturante $b$.\n",
        "\n",
        "Salve as imagens resultantes na pasta **figsResultado** com os nomes: \"ex08_filtro1morfologia1.png\", \"ex08_filtro2morfologia1.png\", \"ex08_filtro1morfologia2.png\", \"ex08_filtro2morfologia2.png\".\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lê a imagem lena_noise.png\n",
        "img = cv2.imread('figs/lena_noise.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Cria o elemento estruturante\n",
        "b = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "\n",
        "# Aplica a abertura para obter o top-hat\n",
        "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, b)\n",
        "\n",
        "# Aplica o fechamento para obter o bottom-hat\n",
        "bottomhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, b)\n",
        "\n",
        "# Aplica o realce combinando top-hat e bottom-hat\n",
        "realce1 = cv2.add(img, tophat)\n",
        "realce1 = cv2.subtract(realce1, bottomhat)\n",
        "\n",
        "# Aplica a equação apresentada\n",
        "erosao = cv2.erode(img, b)\n",
        "dilatacao = cv2.dilate(img, b)\n",
        "diff1 = cv2.subtract(img, erosao)\n",
        "diff2 = cv2.subtract(dilatacao, img)\n",
        "condicao = cv2.compare(diff1, diff2, cv2.CMP_LT)\n",
        "realce2 = np.where(condicao, erosao, img)\n",
        "\n",
        "# Salva as imagens resultantes\n",
        "cv2.imwrite('figsResultado/ex08_filtro1morfologia1.png', tophat)\n",
        "cv2.imwrite('figsResultado/ex08_filtro2morfologia1.png', bottomhat)\n",
        "cv2.imwrite('figsResultado/ex08_filtro1morfologia2.png', realce1)\n",
        "cv2.imwrite('figsResultado/ex08_filtro2morfologia2.png', realce2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g69Lv-PrDF22",
        "outputId": "c4206f58-908b-42e0-8df9-05e09c39ffc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHgej72s00KD"
      },
      "source": [
        "----\n",
        "## Exercicio 9\n",
        "\n",
        "Por meio das técnicas aprendidas na disciplina, tente melhorar o **máximo** possível a imagem **figs/lena_pontilhada.png**. Salve a imagem resultante na pasta **figsResultado** com o nome **ex09.png**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAYlA288FV11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGLYOqXm00KE"
      },
      "source": [
        "----\n",
        "## Exercício 10\n",
        "\n",
        "Crie duas funções chamadas **esteg** e **decodificaEsteg**. A primeira função deve implementar uma técnica de esteganografia que consiste em camuflar uma mensagem em uma imagem. A segunda função deve decodificar a imagem gerada pela primeira.\n",
        "\n",
        "A função **esteg** deve receber uma determinada imagem de entrada e uma string. Você deverá criar uma cópia da imagem passada como entrada e deverá gravar a string nela de forma que ela fique imperceptível, mesmo com zoom na imagem.\n",
        "\n",
        "- Uma forma de atingir esse objetivo é escrever a string em uma imagem nova auxiliar. Depois usar limiarização para transformar os tons de cinza dela. Por fim, você pode usar uma operação aritmética para adicionar essa nova imagem na imagem passada como parâmetro da função.\n",
        "\n",
        "- Você pode usar a função **putText** da biblioteca OpenCV para escrever uma string em uma imagem.\n",
        "\n",
        "- Você pode considerar como premissa aumentar ou diminuir um único tom de cinza em alguns pixels de uma imagem qualquer irá gerar uma alteração visualmente imperceptível. \n",
        "\n",
        "\n",
        "A função **decodificaEsteg** deve receber duas imagem. A primeira delas é uma imagem que contém uma mensagem escondida. A segunda imagem é a original antes da operação de esteganografia. A função deve retornar uma nova imagem que torne visível a mensagem camuflada possibilitante a leitura dela.\n",
        "\n",
        " - Uma operação aritmética pode ser usada para extrair a imagem escondida\n",
        " - A limiarização pode ser usada para transformar os tons de cinza da mensagem escondida em um tom de cinza desejado para facilitar a visualização.\n",
        " \n",
        "Use a função **esteg** para esconder a string dentro da imagem **facens2.jpg**, mostre a imagem resultante na tela e salve na pasta **figsResultado** com o nome **ex10_esteganografia.png**\n",
        "\n",
        "Use a função **decodificaEsteg** para revelar a mensagem contida dentro da imagem retornada pela primeira função. Mostre a imagem resultante na tela e salve na pasta **figsResultado** com o nome **ex10_mesgDecodificada.png**.\n",
        "\n",
        "Obs: as funções acima devem ser genéricas, ou seja, devem funcionar para quaisquer imagens passadas como entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FiHEvYQN00KE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1e3aeb07-1dcf-4514-82bd-224b6ef02b91"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b460d0014338>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Exibe a imagem resultante na tela\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Imagem Esteganografada\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagem_esteg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def esteg(imagem, mensagem):\n",
        "    # Converte a mensagem em uma sequência de bytes\n",
        "    mensagem_bytes = mensagem.encode('utf-8')\n",
        "    tamanho_mensagem = len(mensagem_bytes)\n",
        "\n",
        "    # Verifica se a imagem tem espaço suficiente para a mensagem\n",
        "    altura, largura, _ = imagem.shape\n",
        "    tamanho_imagem = altura * largura * 3\n",
        "    tamanho_bytes = len(mensagem_bytes) * 8\n",
        "\n",
        "    if tamanho_bytes > tamanho_imagem:\n",
        "        raise ValueError(\"A imagem não tem espaço suficiente para a mensagem.\")\n",
        "\n",
        "    # Codifica o tamanho da mensagem nos primeiros 32 bits da imagem\n",
        "    for i in range(32):\n",
        "        bit = (tamanho_mensagem >> i) & 1\n",
        "        imagem.itemset((i // largura, i % largura, 2), bit * 255)\n",
        "\n",
        "    # Codifica a mensagem na imagem\n",
        "    indice_byte = 0\n",
        "    for i in range(32, tamanho_bytes + 32):\n",
        "        bit = (mensagem_bytes[indice_byte >> 3] >> (indice_byte & 7)) & 1\n",
        "        imagem.itemset((i // largura, i % largura, 2), bit * 255)\n",
        "        indice_byte += 1\n",
        "\n",
        "    return imagem\n",
        "\n",
        "def decodificaEsteg(imagem_esteg):\n",
        "    # Obtém a altura e largura da imagem esteganografada\n",
        "    altura, largura, _ = imagem_esteg.shape\n",
        "\n",
        "    # Cria uma imagem vazia para armazenar a mensagem decodificada\n",
        "    imagem_decodificada = np.zeros((altura, largura), dtype=np.uint8)\n",
        "\n",
        "    # Itera sobre os pixels da imagem esteganografada\n",
        "    for i in range(altura):\n",
        "        for j in range(largura):\n",
        "            # Obtém o valor do pixel na imagem esteganografada\n",
        "            pixel_esteg = imagem_esteg[i, j]\n",
        "\n",
        "            # Obtém o último bit do valor do pixel (mensagem oculta)\n",
        "            bit_oculto = pixel_esteg & 1\n",
        "\n",
        "            # Adiciona o bit na imagem decodificada\n",
        "            imagem_decodificada[i, j] = bit_oculto\n",
        "\n",
        "    return imagem_decodificada\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}